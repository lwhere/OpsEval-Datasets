name,Faithfulness,Answer_Relevancy,Answer_Correctness,Answer_Similarity
Gpt-3.5-Turbo,0.42171467364950055,0.8691295573045116,0.6038112679436712,0.870169867075605
Qwen1.5-4B-Chat,0.38204865489701556,0.8389697689558571,0.5521128189924648,0.8573317706502359
Baichuan2-13B-Chat,0.4038672142368241,0.8192887757169468,0.5623602404354114,0.8562630521329339
Qwen1.5-14B-Chat,0.4991210277214334,0.7953872813217998,0.5891222801836271,0.8588771162081673
Yi-6B-Chat,0.7600815667858686,0.7912540642980099,0.7610564816532298,0.6761740477117962
Vicuna-7B-V1.5,0.39214979579762405,0.7771452487068145,0.44308513423549384,0.819478102998531
Baichuan2-7B-Chat,0.3683127572016461,0.7749038932071436,0.5101570739448591,0.8504995667294786
Qwen1.5-0.5B-Chat,0.2617687074829932,0.7710346032394836,0.4777335192926036,0.8346118169208395
Qwen1.5-1.8B-Chat,0.5491781930806321,0.769059886385716,0.5344330706846868,0.8437705436461957
Qwen1.5-7B-Chat,0.7231431514350063,0.6963952727655642,0.7350526525675435,0.6957602523500673
Vicuna-13B-V1.5,0.613175326243208,0.682444153024839,0.5924435357123905,0.6493806776292096
Internlm2-Chat-20B,0.7918762142818747,0.6187939679354695,0.5756624792803415,0.8195634463645642
Mistral-7B,0.6409280685903916,0.4271051397084787,0.453115837113527,0.6903975251587856
Yi-6B,0.366171888675488,0.35434640725576727,0.48557644112672105,0.7941020553273606
Gemma-7B,0.4059392201442353,0.35160449208958283,0.5377158689736348,0.7911868222195938
Gemma-2B,0.45988486660889083,0.33416817486815076,0.4592030663597664,0.744093765199015
Internlm2-Chat-7B,0.46693736812083075,0.30772894154056324,0.6038537202079961,0.7424094998006903
